{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(2333)\n",
    "torch.cuda.manual_seed(2333)\n",
    "np.random.seed(2333)\n",
    "random.seed(2333)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbs = json.load(open(\"data/tables.json\"))\n",
    "train_other = json.load(open(\"data/train_others.json\"))\n",
    "train_spider = json.load(open(\"data/train_spider.json\"))\n",
    "dev = json.load(open(\"data/dev.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_size = 128\n",
    "query_size = 380\n",
    "bert_size = 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align(x, size):\n",
    "    if len(x) < size:\n",
    "        return x + [0] * (size - len(x))\n",
    "    return x[:size - 1] + [102]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DB_sen = {}\n",
    "for d in dbs:\n",
    "    s = \"[CLS] \" + d[\"db_id\"] + \" [SEP]\"\n",
    "    for i in range(len(d[\"table_names\"])):\n",
    "        t = d[\"table_names\"][i]\n",
    "        s += \" \" + t\n",
    "        for j, c in d[\"column_names\"]:\n",
    "            if j == i:\n",
    "                s += \" \" + c\n",
    "        s += \" [SEP]\"\n",
    "    DB_sen[d[\"db_id\"]] = s\n",
    "DB_tok = {k: align(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(v)), DB_size) for k, v in DB_sen.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos, neg = [], []\n",
    "for train_data in [train_other, train_spider, dev]:\n",
    "    for i in range(len(train_data)):\n",
    "        q = \"[CLS] \" + train_data[i][\"question\"] + \" [SEP]\"\n",
    "        q_tok = align(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(q)), query_size)\n",
    "        for k, v in DB_tok.items():\n",
    "            if k == train_data[i][\"db_id\"]:\n",
    "                pos.append((q_tok, v))\n",
    "            else:\n",
    "                neg.append((q_tok, v))\n",
    "# pos = random.sample(pos, 1000)\n",
    "neg_sam = random.sample(neg, len(pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pos + neg_sam\n",
    "y = [1] * len(pos) + [0] * len(neg_sam)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y, device):\n",
    "        # self.Xq = torch.tensor([x[0] for x in X]).to(device)\n",
    "        self.Xd = torch.tensor([x[0] + x[1] for x in X]).to(device)\n",
    "        self.Xt = torch.tensor([ [0] * len(x[0]) + [1] * len(x[1]) for x in X]).to(device)\n",
    "        self.y = torch.Tensor(y).to(device)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return (self.Xd[index], self.Xt[index]), self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "train_data = MyDataset(X_train, y_train, device)\n",
    "train_iter = torch.utils.data.DataLoader(train_data, batch_size, shuffle=True)\n",
    "val_data = MyDataset(X_val, y_val, device)\n",
    "val_iter = torch.utils.data.DataLoader(val_data, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(net, self).__init__()\n",
    "        self.MD = nn.ModuleDict({\n",
    "            \"encoder\": BertModel.from_pretrained('bert-base-uncased'),\n",
    "            # \"query_encoder\": BertModel.from_pretrained('bert-base-uncased'),\n",
    "            # \"db_encoder\": BertModel.from_pretrained('bert-base-uncased'),\n",
    "            \"linear1\": nn.Linear(bert_size, 768),\n",
    "            \"linear2\": nn.Linear(768, 300),\n",
    "            \"linear3\": nn.Linear(300, 1)\n",
    "        })\n",
    "        \n",
    "        for submodel in [self.MD[\"encoder\"]]:\n",
    "            for param in submodel.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        db, tok = x\n",
    "        x = self.MD['encoder'](db, token_type_ids=tok)\n",
    "        # Q = self.MD[\"query_encoder\"](query)\n",
    "        # D = self.MD[\"db_encoder\"](db)\n",
    "#         x = torch.sum(Q[0][:, 0, :] * D[0][:, 0, :], axis=-1)\n",
    "#         print(x)\n",
    "        # x = torch.cat([Q[0][:, 0, :], D[0][:, 0, :]], -1)\n",
    "        x = torch.nn.functional.relu(self.MD[\"linear1\"](x[0][:, 0, :]))\n",
    "        x = torch.nn.functional.relu(self.MD[\"linear2\"](x))\n",
    "        x = self.MD[\"linear3\"](x)\n",
    "        return torch.sigmoid(x).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "loss = nn.BCELoss()\n",
    "model = net().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val_loss = np.inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 , train acc: 0.7756634378403164 , train loss: 0.47331092499771754 , val acc: 0.8638473439917483 , val loss: 0.34956999823965934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [06:01<2:54:44, 361.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 , train acc: 0.8145239869318508 , train loss: 0.41194747128295045 , val acc: 0.8638473439917483 , val loss: 0.32435881788542187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [12:04<2:48:55, 362.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 , train acc: 0.8221470739955293 , train loss: 0.3940079486092681 , val acc: 0.888602372356885 , val loss: 0.2768116463580932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [18:07<2:42:59, 362.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 , train acc: 0.8266750730784662 , train loss: 0.3886981969741434 , val acc: 0.9004641567818463 , val loss: 0.2435047569155862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [24:10<2:37:08, 362.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 , train acc: 0.8355018054679888 , train loss: 0.37569937475664933 , val acc: 0.8710675605982465 , val loss: 0.3337915395821198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/30 [30:12<2:30:54, 362.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 , train acc: 0.8331518312603886 , train loss: 0.3773750911213275 , val acc: 0.8994326972666323 , val loss: 0.24792185681571877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [36:13<2:24:44, 361.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 , train acc: 0.8317189201581934 , train loss: 0.37611793514144465 , val acc: 0.8648788035069623 , val loss: 0.29796477147080713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7/30 [42:26<2:20:04, 365.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 , train acc: 0.8398005387745744 , train loss: 0.36524744657668823 , val acc: 0.8958225889633832 , val loss: 0.24929008474780026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8/30 [48:46<2:15:33, 369.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 , train acc: 0.8373932481228864 , train loss: 0.3691252212579212 , val acc: 0.8839608045384219 , val loss: 0.26550222943763163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9/30 [54:50<2:08:48, 368.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 , train acc: 0.8387688427809938 , train loss: 0.36901766954127263 , val acc: 0.8855079938112429 , val loss: 0.2601596328173872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10/30 [1:00:52<2:02:03, 366.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11 , train acc: 0.8349286410271107 , train loss: 0.3711593294458662 , val acc: 0.8648788035069623 , val loss: 0.3410001698710397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [1:07:14<1:57:29, 371.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12 , train acc: 0.8461053476242334 , train loss: 0.3526922979621058 , val acc: 0.8746776689014956 , val loss: 0.2871675381927822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 12/30 [1:13:16<1:50:26, 368.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13 , train acc: 0.8461626640683212 , train loss: 0.3592200407518892 , val acc: 0.8798349664775658 , val loss: 0.2870970961175256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13/30 [1:19:17<1:43:42, 366.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14 , train acc: 0.8433541583080185 , train loss: 0.3608841309849701 , val acc: 0.8540484785972151 , val loss: 0.35538046729816736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14/30 [1:25:19<1:37:17, 364.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15 , train acc: 0.8476528916146042 , train loss: 0.3505440090256666 , val acc: 0.8963383187209902 , val loss: 0.24327004597920496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 15/30 [1:31:22<1:31:02, 364.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16 , train acc: 0.8460480311801456 , train loss: 0.3525548924339079 , val acc: 0.8757091284167097 , val loss: 0.32598065405165705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 16/30 [1:37:23<1:24:45, 363.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17 , train acc: 0.8436407405284576 , train loss: 0.351726759407263 , val acc: 0.8922124806601341 , val loss: 0.2632978449500194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 17/30 [1:43:24<1:18:34, 362.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18 , train acc: 0.8447870694102138 , train loss: 0.35019818518953266 , val acc: 0.9014956162970603 , val loss: 0.24117081373009702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 18/30 [1:49:26<1:12:30, 362.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19 , train acc: 0.8484553218318336 , train loss: 0.35011018893708745 , val acc: 0.8777720474471377 , val loss: 0.3065447244407007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 19/30 [1:55:27<1:06:22, 362.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20 , train acc: 0.8514930933684874 , train loss: 0.3449486609689894 , val acc: 0.8947911294481692 , val loss: 0.24333819406767015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20/30 [2:01:28<1:00:17, 361.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21 , train acc: 0.847423625838253 , train loss: 0.34869704409411434 , val acc: 0.8855079938112429 , val loss: 0.28483107632151916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [2:07:29<54:13, 361.52s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22 , train acc: 0.852524789362068 , train loss: 0.3450944662784214 , val acc: 0.887570912841671 , val loss: 0.26913150288395166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22/30 [2:13:30<48:11, 361.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23 , train acc: 0.8474809422823408 , train loss: 0.35110617176935843 , val acc: 0.8947911294481692 , val loss: 0.26102334395235444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 23/30 [2:19:32<42:09, 361.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24 , train acc: 0.8517796755889264 , train loss: 0.34384418773232284 , val acc: 0.8803506962351728 , val loss: 0.3169468157560156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 24/30 [2:25:33<36:07, 361.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25 , train acc: 0.851034561815785 , train loss: 0.343119202870834 , val acc: 0.8968540484785972 , val loss: 0.2509664765791127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 25/30 [2:31:34<30:06, 361.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26 , train acc: 0.8487419040522726 , train loss: 0.34763331503665035 , val acc: 0.8757091284167097 , val loss: 0.30562744237090617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26/30 [2:37:36<24:05, 361.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27 , train acc: 0.8514357769243996 , train loss: 0.33821355033694295 , val acc: 0.8999484270242393 , val loss: 0.24912439139325473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 27/30 [2:43:37<18:04, 361.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28 , train acc: 0.8518943084771021 , train loss: 0.3405599669224144 , val acc: 0.8922124806601341 , val loss: 0.2570986036742476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 28/30 [2:49:38<12:02, 361.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29 , train acc: 0.8502321315985556 , train loss: 0.3435351856694718 , val acc: 0.850954100051573 , val loss: 0.3680391599995273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29/30 [2:55:40<06:01, 361.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 , train acc: 0.8524674729179802 , train loss: 0.34152348537448346 , val acc: 0.888602372356885 , val loss: 0.253034257273804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [3:01:40<00:00, 361.19s/it]\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(1, epochs + 1)):\n",
    "    model.train()\n",
    "    l_sum, acc, n = 0.0, 0, 0\n",
    "    for X, y in train_iter:\n",
    "        y_pred = model(X)\n",
    "        l = loss(y_pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "        l_sum += l.item() * y.shape[0]\n",
    "        acc += torch.sum((y_pred > 0.5) == (y == 1)).item()\n",
    "        n += y.shape[0]\n",
    "    model.eval()\n",
    "    l_sum_val, acc_val, n_val = 0.0, 0, 0\n",
    "    for X, y in val_iter:\n",
    "        y_pred = model(X)\n",
    "        l = loss(y_pred, y)\n",
    "        l_sum_val += l.item() * y.shape[0]\n",
    "        acc_val += torch.sum((y_pred > 0.5) == (y == 1)).item()\n",
    "        n_val += y.shape[0]\n",
    "    val_loss = l_sum_val / n_val\n",
    "    if val_loss < min_val_loss:\n",
    "        min_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"save/best_model.pt\")\n",
    "    print(\"epoch\", epoch, \", train acc:\", acc / n, \", train loss:\", l_sum / n, \", val acc:\", acc_val / n_val,  \", val loss:\", val_loss, flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
